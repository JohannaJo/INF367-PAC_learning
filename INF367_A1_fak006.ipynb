{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF367 Assignment 1, Exercise 2\n",
    "Author: Johanna JÃ¸sang (fak006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "n = 10 #number of variables\n",
    "delta = 0.1\n",
    "eps = 0.1\n",
    "\n",
    "ten_div_delta = int(10/delta)\n",
    "m = int(((2*n) / eps) * ((np.log(2*n) + np.log(1/delta))))\n",
    "N = int((20/eps)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about methods used for PAC implementation\n",
    "Since a hypothesis only can be given positive examples if the target is satisfiable, only satisfiable targets are used in this implementation. A satisfiable target is generated by combining data generated using a normal distribution. \"1\" indicates that a variable is evaluated to True, \"0\" that is is evaluated to False. The target does not necessarily contain all literals, hence it may contain \"3\" which indicated that this variable is not present in the target. \\\n",
    "Target generation example:\\\n",
    "[0, 1, 1, 0, 0, 0, 1, 1, 0, 0] <- basis 1 and \\\n",
    "[0, 1, 1, 0, 1, 0, 0, 0, 0, 1] <- basis 2 generate:\\\n",
    "[0, 1, 1, 0, 3, 0, 3, 3, 0, 3] <- target\n",
    "\n",
    "Examples are generated in the same way as bases for the target, by normal distribution. Each example is categorized by whether it satisfies the target or not. The following examples are based on the target given above. Notice that the valuation of a variable not present in the target has no influence on the categorization.\n",
    "\n",
    "([0, 1, 1, 1, 0, 0, 1, 1, 0, 1],  0) <- valuation that doesn't satisfy target \\\n",
    "([0, 1, 1, 0, 1, 0, 1, 0, 0, 0],  1) <- valuation that does satisfy target \n",
    "\n",
    "Before training, the hypothesis looks like this [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], where the \"2\" indicates that both the variable and its negation are evaluated to true.\n",
    "Here is a depiction of a training iteration, where only two positive examples were given.\n",
    "H: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2] <- initial hypothesis \\\n",
    "  ([0, 1, 1, 0, 1, 0, 1, 0, 0, 0], 1) <- positive example 1 \\\n",
    "H: [0, 1, 1, 0, 1, 0, 1, 0, 0, 0]  <- hypothesis after updating from example 1 \\\n",
    "  ([0, 1, 1, 0, 0, 0, 1, 0, 0, 0], 1) <- positive example 2 \\\n",
    "H: [0, 1, 1, 0, 3, 0, 1, 0, 0, 0] <- hypothesis after updating from example 2 \n",
    "\n",
    "If we compare the target and the final hypothesis we can see the result. \\\n",
    "Target-----: [0, 1, 1, 0, 3, 0, 3, 3, 0, 3] \\\n",
    "Trained hyp: [0, 1, 1, 0, 3, 0, 1, 0, 0, 0] \n",
    "\n",
    "The hypothesis has not quite reached the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_uncategorized_data(size, dimensions):\n",
    "    \"\"\"\n",
    "    Using a random normal distribution, 2D datasets of 1s and 0s are generated\n",
    "    \n",
    "    :param size: number of arrays to generate\n",
    "    :param dimensions: length of each array\n",
    "    :return : 2D array of uncategorized data\n",
    "    \n",
    "    \"\"\"\n",
    "    normal_distribution = np.random.normal(size=[size, dimensions]) >= 0\n",
    "    normal_distribution_ints = normal_distribution.astype(int)                        \n",
    "    return normal_distribution_ints.tolist()\n",
    "\n",
    "def generate_satisfiable_target(size, dimensions):\n",
    "    \"\"\"\n",
    "    Using a random normal distribution, 2D datasets of 1s and 0s are generated\n",
    "    \n",
    "    :param size: number of arrays to generate\n",
    "    :param dimensions: length of each array\n",
    "    \n",
    "    \"\"\"\n",
    "    target_basis_ints = generate_uncategorized_data(size, dimensions)\n",
    "    target = [1]*(len(target_basis_ints[0]))\n",
    "    for j in range (len(target_basis_ints[0])):\n",
    "        column_target_value = 3\n",
    "        column_bool = target_basis_ints[0][j]\n",
    "        use_bool = True\n",
    "        for i in range (len(target_basis_ints)):\n",
    "            if (target_basis_ints[i][j] != column_bool):\n",
    "                column_target_value = 3\n",
    "                use_bool = False\n",
    "                continue\n",
    "        if(use_bool):\n",
    "            if(column_bool == True):\n",
    "                column_target_value = 1\n",
    "            else:\n",
    "                column_target_value = 0\n",
    "        target[j] = column_target_value#\n",
    "    return target\n",
    "    \n",
    "def categorize_data(valuation, target):\n",
    "    \"\"\"\n",
    "    Categorizes valuations based on if they satisfy the target   \n",
    "    \n",
    "    :param valuation: valuation to categorize\n",
    "    :param target: used classify the valuation\n",
    "    :return : 1 if the valuation satisfies the target, 0 otherwise\n",
    "    \n",
    "    \"\"\"\n",
    "    if(len(valuation) != len(target)):\n",
    "        print('data length:', str(len(valuation)), ' != target length', str(len(target)))\n",
    "        return 4 # this should never happen, hence and invalid number is given\n",
    "    for i in range (len(target)):\n",
    "        #if t[i] = 3, d[i] = 2 or t[i] == d[i], d entails t\n",
    "        if((target[i] != 3) and (valuation[i] != 2) and (target[i] != valuation[i])):\n",
    "                return 0 # valuation does not satisfy target\n",
    "    return 1 # valuation does satisfy target\n",
    "\n",
    "def generate_examples(data_list, target):\n",
    "    \"\"\"\n",
    "    Generates a list of tupples where each set of valuations is paired with a classification, ie a positive or negative example.\n",
    "    \n",
    "    :param data: set of uncategorized examples\n",
    "    :param data: \n",
    "    :return : list of categorized valuations\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for valuation in data_list:\n",
    "        category = categorize_data(valuation, target)\n",
    "        examples.append((valuation, category))\n",
    "    return examples\n",
    "\n",
    "def initialize_hypothesis(length):\n",
    "    \"\"\"\n",
    "    Generates a initial hypothesis of a certian length\n",
    "    \n",
    "    :param length: length of hypothesis to generate\n",
    "    :return : initial hypothesis in the form of a list of 2s\n",
    "    \"\"\"\n",
    "    return [2] * length\n",
    "\n",
    "def train_hypothesis(training_set, hypothesis):\n",
    "    \"\"\"\n",
    "    Uses the algorithm for learning a conjunction of literals. Positive examples in the training set are used to update the hypothesis.\n",
    "    \n",
    "    Uncomment the commented lines to read information about the training.\n",
    "    \n",
    "    :param training_set: list of categorized valuations\n",
    "    :param hypothesis: valuation to update\n",
    "    :return : trained hypothesis\n",
    "    \"\"\"\n",
    "    #n_of_pos = 0\n",
    "    for e in training_set:\n",
    "        if (e[1] == 1):\n",
    "            # print(e)\n",
    "            #n_of_pos = n_of_pos + 1\n",
    "            e_variables = e[0]\n",
    "            for i in range(len(e_variables)):\n",
    "                if ((e_variables[i] != hypothesis[i]) and (hypothesis[i] != 3)):\n",
    "                    if(hypothesis[i] == 2):\n",
    "                        hypothesis[i] = e_variables[i]\n",
    "                    else:\n",
    "                        hypothesis[i] = 3\n",
    "            #print('H:', hypothesis)\n",
    "    #print('Pos exampes / set size: ', n_of_pos, '/', len(training_set))                    \n",
    "    #print('Target:            ', target)\n",
    "    #print('Trained hypothesis:', hypothesis)\n",
    "    return hypothesis\n",
    "\n",
    "def disjoint_union(mt, mh):\n",
    "    \"\"\"\n",
    "    Generated the disjoint union between two sets.\n",
    "    \n",
    "    :param mt: set of valuations that satisfy the target\n",
    "    :param mh: det of valuations that satisfy the hypothesis\n",
    "    :return : disjoint union between mt and mh\n",
    "    \"\"\"\n",
    "    for e in mt:\n",
    "        if e in mh:\n",
    "            mt.remove(e)\n",
    "            mh.remove(e)\n",
    "    for e in mh:\n",
    "        if e in mt:\n",
    "            mt.remove(e)\n",
    "            mh.remove(e)\n",
    "    return mt + mh\n",
    "\n",
    "def calculate_t_hat(S, target, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculates the estimated error of the trained hypothesis w.r.t the target. \n",
    "    \n",
    "    :param S: set of unlabeled examples\n",
    "    :param target: to estimate the error w.r.t\n",
    "    :param hypothesis: to estimate the error of\n",
    "    \"\"\"\n",
    "    mt = [] #set of valuations in S that satisfy the target\n",
    "    mh = [] #set of valuations in S that satisfy the target\n",
    "    for s in S:\n",
    "        if (categorize_data(s, target) == 1):\n",
    "            mt.append(s)\n",
    "        if (categorize_data(s, hypothesis) == 1):\n",
    "            mh.append(s)\n",
    "    error_s = disjoint_union(mt, mh) #find misclassified valuations\n",
    "    t_hat = len(error_s) / len(S) # error = (no. misclassified valuations)/(total no. of valuations)\n",
    "    return t_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAC implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables used: 10\n",
      "Epsilon: 0.1\n",
      "Delta: 0.1\n",
      "m: 1059\n",
      "10/delta: 100\n",
      "N: 40000\n",
      "\n",
      "Number of iterations: 100\n",
      "Number of errors greater than epsilon: 5\n",
      "Bad error rate: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Print out arguments being used\n",
    "print('Number of variables used:', n)\n",
    "print('Epsilon:', eps)\n",
    "print('Delta:', delta)\n",
    "print('m:', m)\n",
    "print('10/delta:', ten_div_delta)\n",
    "print('N:', N)\n",
    "print()\n",
    "\n",
    "print(\"Number of iterations:\", ten_div_delta)\n",
    "bad_error_count = 0 # number of errors larger than epsolin\n",
    "for i in range(ten_div_delta):    \n",
    "    target = generate_satisfiable_target(2,n) # we generate a target with 2 bases\n",
    "    uncategorized_data = generate_uncategorized_data(m, n)\n",
    "    examples = generate_examples(uncategorized_data, target) #generate examples\n",
    "    h = initialize_hypothesis(n)\n",
    "    trained_h = train_hypothesis(examples, h) #train the hypothesis\n",
    "    unlabeled_ex =  generate_uncategorized_data(N, n)\n",
    "    t = calculate_t_hat(unlabeled_ex, target, trained_h) #calculate the error\n",
    "    if (t > eps):\n",
    "        bad_error_count = bad_error_count + 1 # count the number of errors greater than epsilon\n",
    "print('Number of errors greater than epsilon:', bad_error_count)\n",
    "print('Bad error rate:', bad_error_count/ten_div_delta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
